{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XinchengLi0306/aws--instance/blob/main/Spark%20DataFrame%20-%20Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4ZbRwm_NbFc"
      },
      "source": [
        "# Spark DataFrame - Basics\n",
        "\n",
        "Let's start off with the fundamentals of Spark DataFrame.\n",
        "\n",
        "Objective: In this exercise, you'll find out how to start a spark session, read in data, explore the data and manipuluate the data (using DataFrame syntax as well as SQL syntax). Let's get started!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq\n",
        "!pip install -q pyspark findspark"
      ],
      "metadata": {
        "id": "s3lYusO-OWB7"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "# No need to download Sparkâ€”pip installation includes Spark JARs\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"ColabSpark\").getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "57Xb5juLOZIf",
        "outputId": "71a49295-465a-450e-faee-cfa5a16ba86c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7c74eeb22d50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6449fe07683d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>ColabSpark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WrG2dT2O1Z7",
        "outputId": "dca46cb2-57e6-49ec-f5a9-90612e54fec8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dXqLhFY_NbFj",
        "outputId": "41767967-ba3a-4a1c-91f2-7bbab249ef13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pyspark.sql.dataframe.DataFrame'>\n"
          ]
        }
      ],
      "source": [
        "# Let's read in the data. Note that it's in the format of JSON.\n",
        "#change the path\n",
        "df = spark.read.json('/content/drive/MyDrive/aws/people.json')\n",
        "print(type(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M-nBR2INbFj"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z0GYO7nNbFj",
        "outputId": "998cbc08-03c5-4131-904e-3839e5802874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+\n",
            "| age|   name|\n",
            "+----+-------+\n",
            "|NULL|Michael|\n",
            "|  30|   Andy|\n",
            "|  19| Justin|\n",
            "+----+-------+\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['age', 'name']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# The show method allows you visualise DataFrames. We can see that there are two columns.\n",
        "df.show()\n",
        "\n",
        "# You could also try this.\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FGkY3UGNbFk",
        "outputId": "65b2523f-eee5-47f2-f7da-e9441c9ea0fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+-------+\n",
            "|summary|               age|   name|\n",
            "+-------+------------------+-------+\n",
            "|  count|                 2|      3|\n",
            "|   mean|              24.5|   NULL|\n",
            "| stddev|7.7781745930520225|   NULL|\n",
            "|    min|                19|   Andy|\n",
            "|    max|                30|Michael|\n",
            "+-------+------------------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We can use the describe method get some general statistics on our data too. Remember to show the DataFrame!\n",
        "# But what about data type?\n",
        "df.describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm3GsbefNbFk",
        "outputId": "f99e2c41-2973-4184-a1eb-613a254f7c18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: long (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# For type, we can use print schema.\n",
        "# But wait! What if you want to change the format of the data? Maybe change age to an integer instead of long?\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIT2_IceNbFk"
      },
      "source": [
        "## Data Manipulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VgVQTDNjNbFk"
      },
      "outputs": [],
      "source": [
        "# Let's import in the relevant types.\n",
        "from pyspark.sql.types import (StructField,StringType,IntegerType,StructType)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLtEumX0NbFl"
      },
      "outputs": [],
      "source": [
        "# Then create a variable with the correct structure.\n",
        "data_schema = [StructField('age',IntegerType(),True),\n",
        "              StructField('name',StringType(),True)]\n",
        "\n",
        "final_struct = StructType(fields=data_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI-OlnWNNbFl",
        "outputId": "65c342bb-18b0-4970-8fff-f280605c8cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# And now we can read in the data using that schema. If we print the schema, we can see that age is now an integer.\n",
        "df = spark.read.json('/content/drive/MyDrive/Infosys722/Datasets/people.json', schema=final_struct)\n",
        "\n",
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmG6u0LENbFl",
        "outputId": "332638df-9176-48a5-aa78-92d16ce4f6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+\n",
            "| age|\n",
            "+----+\n",
            "|NULL|\n",
            "|  30|\n",
            "|  19|\n",
            "+----+\n",
            "\n",
            "+----+\n",
            "| age|\n",
            "+----+\n",
            "|NULL|\n",
            "|  30|\n",
            "|  19|\n",
            "+----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We can also select various columns from a DataFrame.\n",
        "df.select('age').show()\n",
        "\n",
        "# We could split up these steps, first assigning the output to a variable, then showing that variable. As you see, the output is the same.\n",
        "ageColumn = df.select('age')\n",
        "\n",
        "ageColumn.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TuCL6dXNbFl",
        "outputId": "8d187871-64e2-4c43-be86-d5db864e65e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-------+----------+\n",
            "| age|   name|double_age|\n",
            "+----+-------+----------+\n",
            "|NULL|Michael|      NULL|\n",
            "|  30|   Andy|        60|\n",
            "|  19| Justin|        38|\n",
            "+----+-------+----------+\n",
            "\n",
            "+----+-------+\n",
            "| age|   name|\n",
            "+----+-------+\n",
            "|NULL|Michael|\n",
            "|  30|   Andy|\n",
            "|  19| Justin|\n",
            "+----+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We can also add columns, manipulating the DataFrame.\n",
        "\n",
        "df.withColumn('double_age',df['age']*2).show()\n",
        "\n",
        "# But note that this doesn't alter the original DataFrame. You need to assign the output to a new variable in order to do so.\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itb8rxUaNbFl",
        "outputId": "3337978b-5966-44f1-d2d6-4ef91ceaa3d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+\n",
            "|my_new_age|   name|\n",
            "+----------+-------+\n",
            "|      NULL|Michael|\n",
            "|        30|   Andy|\n",
            "|        19| Justin|\n",
            "+----------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We can rename columns too!\n",
        "df.withColumnRenamed('age', 'my_new_age').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6zZmDsUNbFm"
      },
      "source": [
        "## Introducing SQL\n",
        "We can query a DataFrame as if it were a table! Let's see a few examples of that below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtkNsXvuNbFm"
      },
      "outputs": [],
      "source": [
        "# First, we have to register the DataFrame as a SQL temporary view.\n",
        "df.createOrReplaceTempView('people')\n",
        "\n",
        "# After that, we can use the SQL programming language for queries.\n",
        "results = spark.sql(\"SELECT * FROM people\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyWtmM3eNbFm",
        "outputId": "acb57c5e-dcdc-45a6-a116-1c954a101faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|age|\n",
            "+---+\n",
            "| 30|\n",
            "| 19|\n",
            "+---+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Here's another example:\n",
        "results = spark.sql(\"SELECT age FROM people WHERE age >= 19\")\n",
        "results.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90rn9IzpNbFm"
      },
      "source": [
        "Now that we're done with this tutorial, let's move on to Spark DataFrame Operations!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}